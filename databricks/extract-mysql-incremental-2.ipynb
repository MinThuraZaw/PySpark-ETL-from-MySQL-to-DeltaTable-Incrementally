{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99764021-e9bd-4090-9686-6991be2a3e7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d58e74f0-89b7-4d60-8e87-5380ced782fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# function to read data from MySQL, return DataFrame\n",
    "# don't add ; at the end of query\n",
    "# set useLegacyDatetimeCode to false if you want the utc timestamp from timestamp columns\n",
    "# use databricks secrets for username and passowrd\n",
    "\n",
    "def read_from_mysql(database_name, query):\n",
    "    try:\n",
    "        df = (\n",
    "            spark.read.format(\"jdbc\")\n",
    "            .option(\"driver\", \"org.mariadb.jdbc.Driver\")\n",
    "            .option(\n",
    "                \"url\",\n",
    "                f\"host_address/{database_name}?useLegacyDatetimeCode=false\",\n",
    "            )\n",
    "            .option(\"dbtable\", f\"({query}) as result\")\n",
    "            .option(\"user\", dbutils.secrets.get(\"jdbc\", \"demo_username\"))\n",
    "            .option(\"password\", dbutils.secrets.get(\"jdbc\", \"demo_password\"))\n",
    "            .load()\n",
    "        )\n",
    "    except Exception as error:\n",
    "        return error\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcceded0-c22e-46cd-b48c-7528b60570b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Example 2 <br>\n",
    "When the source table is insert only, then we can use watermark table or any way to get the current max id. That way, we can read the changes rows only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0679418-af00-40ce-a614-869d64349c98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table demo_catalog.demo_schema.user_events (\n",
    "  id bigint,\n",
    "  user_id,\n",
    "  event_id,\n",
    "  value,\n",
    "  timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b778854c-6329-4fb1-a1f9-9028f2555596",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table demo_catalog.demo_schema.watermark_table(\n",
    "  table_name string,\n",
    "  max_id long\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6e08bf8-4057-4697-b9a1-e57a95993df8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- start with 0\n",
    "insert into demo_catalog.demo_schema.watermark_table (table_name, max_id) values (\"user_events\", 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c387c73b-f4e2-4edc-9dd5-a3487dde3208",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#get maximum id from the watermark table\n",
    "df_current = spark.sql(\"select max_id from demo_catalog.demo_schema.watermark_table where table_name = 'user_events' \")\n",
    "df_current = df_current.select(\"max_id\").collect()[0]\n",
    "current_max_id = df_current[\"max_id\"]\n",
    "\n",
    "#get maximum id from the source table\n",
    "df_source = read_from_mysql(\"demo_database\", \"select max(id) as max_id from demo_database.user_events \")\n",
    "df_source = df_source.select(\"max_id\").collect()[0]\n",
    "source_max_id = df_source[\"max_id\"]\n",
    "\n",
    "print(\"current max id:\", current_max_id)\n",
    "print(\"source max id:\", source_max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b676b73a-1f7c-4b89-881d-e46f0c62773b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read only new rows from source table by comparing two ids\n",
    "query = f\"select * from demo_database.user_events where id > '{current_max_id}' and id <= '{source_max_id}' \"\n",
    "\n",
    "new_data = read_from_mysql(\"demo_database\", query)\n",
    "#new_data.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6759d41d-d9cb-471b-bb53-baee6fddd6bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark and delta configs for automerge \n",
    "# so we don't need to worry for new schema or deleted schema \n",
    "\n",
    "if spark.conf.get(\"spark.databricks.delta.schema.autoMerge.enabled\") == \"false\":\n",
    "    spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")\n",
    "    print(\"set to true\")\n",
    "elif spark.conf.get(\"spark.databricks.delta.schema.autoMerge.enabled\") == \"true\":\n",
    "    print(\"true\")\n",
    "else:\n",
    "    print(\"unknown value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05eedc31-6690-4ea3-86f3-8fe4b8938aae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forName(spark, \"demo_catalog.demo_schema.user_events\")\n",
    "\n",
    "(\n",
    "    deltaTable.alias(\"current\")\n",
    "    .merge(new_data.alias(\"new\"), \"new.id = current.id\")\n",
    "    .whenMatchedUpdateAll()\n",
    "    .whenNotMatchedInsertAll()\n",
    "    .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa0a6cfa-357f-4477-87e1-a277a236b9e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update the watermark table with max id after pipeline is succeed\n",
    "\n",
    "query = f\"update demo_catalog.demo_schema.watermark_table set max_id = '{source_max_id}' where table_name = 'user_events' \"\n",
    "\n",
    "spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d784f8b-5165-40fb-bc6c-d22faae4315e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2567401122121072,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "extract-mysql-incremental-2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
